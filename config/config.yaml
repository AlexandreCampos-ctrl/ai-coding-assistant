llm:
  provider: gemini  # gemini, openai, ollama
  model: models/gemini-flash-latest
  temperature: 0.7
  max_tokens: 2000
  api_keys:
    gemini: ""         # Adicione sua API key aqui ou no .env
    openai: ""
    anthropic: ""

tools:
  enabled:
    - file_operations
    - code_executor

code_execution:
  timeout: 30
  allowed_libraries:
    - numpy
    - pandas
    - matplotlib
    - requests

memory:
  max_messages: 50
  context_window: 8000
